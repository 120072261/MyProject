import os
import cv2
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast, GradScaler  # æ··åˆç²¾åº¦è®­ç»ƒ
import segmentation_models_pytorch as smp
import albumentations as A
from albumentations.pytorch import ToTensorV2
from sklearn.model_selection import train_test_split
from tqdm import tqdm  # æ›¿æ¢ tqdm.notebook ä¸º tqdm


# å…¨å±€é…ç½®
class Config:
    SEED = 42
    IMG_SIZE = 512  # è¾“å…¥å°ºå¯¸
    BATCH_SIZE = 16  # P100 æ˜¾å­˜é€‚é… (EffNet-B4 æ¯”è¾ƒå¤§ï¼Œè®¾12æˆ–16)
    EPOCHS = 20  # è®­ç»ƒè½®æ•°
    LR = 2e-4  # å­¦ä¹ ç‡
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    NUM_WORKERS = 2  # é™ä½å·¥ä½œè¿›ç¨‹æ•°ï¼Œé¿å… Kaggle èµ„æºæº¢å‡º
    CHECKPOINT_PATH = "checkpoint.pth"  # æ£€æŸ¥ç‚¹ä¿å­˜è·¯å¾„


def seed_everything(seed):
    torch.manual_seed(seed)
    np.random.seed(seed)
    torch.cuda.manual_seed(seed)
    # æ–°å¢ï¼šå›ºå®š cudnn ç§å­ï¼Œç¡®ä¿ç»“æœå¯å¤ç°
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


seed_everything(Config.SEED)
print(f"Device: {Config.DEVICE}")  # 3. æ™ºèƒ½è·¯å¾„æœç´¢ä¸åŒ¹é…


# ==========================================
def find_dataset_root():
    possible_roots = [
        '/kaggle/input/recodai-luc-scientific-image-forgery-detection',
        '/kaggle/input/scientific-image-forgery-detection',
        './'
    ]
    for path in possible_roots:
        if os.path.exists(os.path.join(path, 'train_images')):
            return path
    return None


ROOT_DIR = find_dataset_root()
if not ROOT_DIR:
    raise ValueError("âŒ æœªæ‰¾åˆ°æ•°æ®é›†è·¯å¾„ï¼è¯·æ£€æŸ¥ Input ç›®å½•ã€‚")

print(f"âœ… æ•°æ®é›†æ ¹ç›®å½•: {ROOT_DIR}")

# å®šä¹‰è·¯å¾„
TRAIN_IMG_DIR = os.path.join(ROOT_DIR, 'train_images')
TRAIN_MASK_DIR = os.path.join(ROOT_DIR, 'train_masks')
if not os.path.exists(TRAIN_MASK_DIR):
    TRAIN_MASK_DIR = os.path.join(TRAIN_IMG_DIR, 'train_masks')  # å¤‡ç”¨è·¯å¾„


# é€’å½’è·å–æ‰€æœ‰æ–‡ä»¶
def get_all_files(directory, extensions):
    files = []
    for ext in extensions:
        files.extend(glob.glob(os.path.join(directory, '**', ext), recursive=True))
    return sorted(list(set(files)))


# 1. æ”¶é›†æ‰€æœ‰å›¾ç‰‡
image_files = get_all_files(TRAIN_IMG_DIR, ['*.jpg', '*.png', '*.tif', '*.tiff'])

# 2. æ”¶é›†æ‰€æœ‰ Mask (åŒ…æ‹¬ .npy)
mask_files = get_all_files(TRAIN_MASK_DIR, ['*.jpg', '*.png', '*.npy'])
# å»ºç«‹ Mask ç´¢å¼•å­—å…¸: { 'case_id': 'full_path' }
mask_map = {os.path.basename(p).split('.')[0]: p for p in mask_files}

# 3. æ„å»º DataFrame
data = []
for img_path in image_files:
    case_id = os.path.basename(img_path).split('.')[0]

    # åˆ¤æ–­æ˜¯å¦ authentic (æ ¹æ®è·¯å¾„å)
    label = 'authentic' if 'authentic' in img_path.lower() else 'forged'

    # å°è¯•åŒ¹é… Mask
    mask_path = mask_map.get(case_id)

    # ä¿®æ­£é€»è¾‘ï¼šå¦‚æœæ˜¯ Authenticï¼Œå¼ºåˆ¶ Mask ä¸º None
    if label == 'authentic':
        mask_path = None

    data.append({
        'case_id': case_id,
        'image_path': img_path,
        'mask_path': mask_path,
        'label': label
    })

df = pd.DataFrame(data)
print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
print(f"æ€»æ ·æœ¬æ•°: {len(df)}")
print(df['label'].value_counts())
print(f"æˆåŠŸåŒ¹é… Mask çš„ Forged æ ·æœ¬: {df[df['label'] == 'forged']['mask_path'].notnull().sum()}")  # æ•°æ®é›†å®šä¹‰


class SIFDataset(Dataset):
    def __init__(self, dataframe, transform=None):
        self.df = dataframe.reset_index(drop=True)
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]

        # --- 1. Image ---
        image = cv2.imread(row['image_path'])
        if image is None:
            image = np.zeros((Config.IMG_SIZE, Config.IMG_SIZE, 3), dtype=np.uint8)
        else:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        h, w = image.shape[:2]

        # --- 2. Mask ---
        mask_path = row['mask_path']

        if mask_path is None:
            mask = np.zeros((h, w), dtype=np.float32)

        else:
            if mask_path.endswith('.npy'):
                try:
                    mask = np.load(mask_path)
                except Exception:
                    mask = np.zeros((h, w), dtype=np.float32)
            else:
                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                if mask is None:
                    mask = np.zeros((h, w), dtype=np.float32)

            # ===== ç¬¬ä¸€æ¬¡å‹ç»´ï¼ˆnumpy é˜¶æ®µï¼‰=====
            if mask.ndim == 3:
                # HWC æˆ– CHW
                if mask.shape[0] == h and mask.shape[1] == w:
                    mask = mask.max(axis=2)
                else:
                    mask = mask.max(axis=0)

            # å¯¹é½å°ºå¯¸
            if mask.shape != (h, w):
                mask = cv2.resize(mask.astype(np.float32),
                                  (w, h),
                                  interpolation=cv2.INTER_NEAREST)

            mask = (mask > 0).astype(np.float32)

        # --- 3. Augmentation ---
        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask']

        # ===== ç¬¬äºŒæ¬¡å‹ç»´ï¼ˆtensor é˜¶æ®µï¼Œå…³é”®ï¼ï¼‰=====
        if isinstance(mask, torch.Tensor):
            if mask.ndim == 3:
                mask = mask.max(dim=0).values  # [H, W]
            elif mask.ndim != 2:
                raise RuntimeError(f"Invalid mask tensor shape: {mask.shape}")

        return image, mask.unsqueeze(0)  # [1, H, W]# æ•°æ®å¢å¼º


def get_transforms(phase):
    if phase == 'train':
        return A.Compose([
            A.Resize(Config.IMG_SIZE, Config.IMG_SIZE),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.5),
            A.RandomRotate90(p=0.5),
            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.5),
            A.OneOf([
                A.GaussNoise(var_limit=(10.0, 50.0)),
                A.GaussianBlur(),
                A.MotionBlur(),
            ], p=0.3),
            A.Normalize(),
            ToTensorV2(),
        ], is_check_shapes=False)
    else:
        return A.Compose([
            A.Resize(Config.IMG_SIZE, Config.IMG_SIZE),
            A.Normalize(),
            ToTensorV2(),
        ], is_check_shapes=False)


# åˆ’åˆ†æ•°æ®é›†
train_df, val_df = train_test_split(df, test_size=0.15, stratify=df['label'], random_state=Config.SEED)

train_ds = SIFDataset(train_df, transform=get_transforms('train'))
val_ds = SIFDataset(val_df, transform=get_transforms('val'))

train_loader = DataLoader(train_ds, batch_size=Config.BATCH_SIZE, shuffle=True,
                          num_workers=Config.NUM_WORKERS, pin_memory=True, drop_last=True)
val_loader = DataLoader(val_ds, batch_size=Config.BATCH_SIZE, shuffle=False,
                        num_workers=Config.NUM_WORKERS, pin_memory=True)

print("âœ… DataLoader å‡†å¤‡å°±ç»ª")  # æ„å»ºæ¨¡å‹


def build_model():
    model = smp.UnetPlusPlus(
        encoder_name="efficientnet-b4",  # å¼ºåŠ› Backbone
        encoder_weights="imagenet",  # é¢„è®­ç»ƒæƒé‡åŠ é€Ÿæ”¶æ•›
        in_channels=3,
        classes=1,
        activation=None,  # è¾“å‡º Logitsï¼Œåœ¨ Loss ä¸­åš Sigmoid
    )
    return model


model = build_model()
model.to(Config.DEVICE)
print("âœ… U-Net++ æ¨¡å‹å·²åŠ è½½ (EfficientNet-B4)")  # æ„å»ºæ¨¡å‹


def build_model():
    model = smp.UnetPlusPlus(
        encoder_name="efficientnet-b4",  # å¼ºåŠ› Backbone
        encoder_weights="imagenet",  # é¢„è®­ç»ƒæƒé‡åŠ é€Ÿæ”¶æ•›
        in_channels=3,
        classes=1,
        activation=None,  # è¾“å‡º Logitsï¼Œåœ¨ Loss ä¸­åš Sigmoid
    )
    return model


model = build_model()
model.to(Config.DEVICE)
print("âœ… U-Net++ æ¨¡å‹å·²åŠ è½½ (EfficientNet-B4)")

# æŸå¤±å‡½æ•°
dice_loss = smp.losses.DiceLoss(mode='binary')
pos_weight = torch.tensor([2.0]).to(Config.DEVICE)
bce_loss = nn.BCEWithLogitsLoss(pos_weight=pos_weight)


def criterion(pred, target):
    return 0.5 * dice_loss(pred, target) + 0.5 * bce_loss(pred, target)


# è¯„ä¼°æŒ‡æ ‡
def compute_scores(pred_logits, target):
    pred_probs = torch.sigmoid(pred_logits)
    pred_mask = (pred_probs > 0.5).float()

    # Intersection & Union
    intersection = (pred_mask * target).sum()
    union = pred_mask.sum() + target.sum()

    iou = (intersection + 1e-7) / (union - intersection + 1e-7)
    f1 = (2 * intersection + 1e-7) / (union + 1e-7)

    return iou.item(), f1.item()


optimizer = optim.AdamW(model.parameters(), lr=Config.LR, weight_decay=1e-3)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.EPOCHS, eta_min=1e-6)
scaler = GradScaler()  # æ··åˆç²¾åº¦

best_loss = float('inf')
history = {'train_loss': [], 'val_loss': [], 'val_f1': []}

print(f"ğŸš€ å¼€å§‹è®­ç»ƒ... (Epochs: {Config.EPOCHS})")


# åŠ è½½æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
def load_checkpoint(model, optimizer, scaler, checkpoint_path=Config.CHECKPOINT_PATH):
    if os.path.exists(checkpoint_path):
        checkpoint = torch.load(checkpoint_path)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        scaler.load_state_dict(checkpoint['scaler_state_dict'])
        epoch = checkpoint['epoch']
        loss = checkpoint['loss']
        print(f"âœ… åŠ è½½æ¨¡å‹ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼ŒEpoch {epoch}, Loss {loss}")
        return model, optimizer, scaler, epoch
    else:
        print("æ²¡æœ‰æ‰¾åˆ°æ£€æŸ¥ç‚¹ï¼Œå¼€å§‹æ–°çš„è®­ç»ƒ")
        return model, optimizer, scaler, 0


model, optimizer, scaler, start_epoch = load_checkpoint(model, optimizer, scaler)

for epoch in range(start_epoch, Config.EPOCHS):
    model.train()
    train_loss = 0

    loop = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{Config.EPOCHS} [Train]", leave=True)
    for imgs, masks in loop:
        imgs, masks = imgs.to(Config.DEVICE), masks.to(Config.DEVICE)

        optimizer.zero_grad()
        with autocast():
            outputs = model(imgs)
            loss = criterion(outputs, masks)

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        train_loss += loss.item()
        loop.set_postfix({"train_loss": f"{loss.item():.4f}"})

    # éªŒè¯æ­¥éª¤
    model.eval()
    val_loss = 0
    val_iou = 0
    val_f1 = 0

    val_loop = tqdm(val_loader, desc=f"Epoch {epoch + 1}/{Config.EPOCHS} [Val]", leave=True)
    with torch.no_grad():
        for imgs, masks in val_loop:
            imgs, masks = imgs.to(Config.DEVICE), masks.to(Config.DEVICE)
            outputs = model(imgs)
            loss = criterion(outputs, masks)

            val_loss += loss.item()
            iou, f1 = compute_scores(outputs, masks)
            val_iou += iou
            val_f1 += f1
            val_loop.set_postfix({"val_loss": f"{loss.item():.4f}", "val_f1": f"{f1:.4f}"})

    # è®¡ç®—å¹³å‡å€¼
    train_loss /= len(train_loader)
    val_loss /= len(val_loader)
    val_iou /= len(val_loader)
    val_f1 /= len(val_loader)

    history['train_loss'].append(train_loss)
    history['val_loss'].append(val_loss)
    history['val_f1'].append(val_f1)

    scheduler.step()

    print(
        f"ğŸ“ Epoch {epoch + 1} Summary | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val F1: {val_f1:.4f}")

    # ä¿å­˜æ£€æŸ¥ç‚¹
    torch.save({
        'epoch': epoch + 1,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'scaler_state_dict': scaler.state_dict(),
        'loss': val_loss
    }, Config.CHECKPOINT_PATH)

    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if val_loss < best_loss:
        best_loss = val_loss
        torch.save(model.state_dict(), "best_model.pth")
        print(f"    >>> ğŸ’¾ Best Model Saved (Val Loss: {val_loss:.4f}, F1: {val_f1:.4f})")

# ç»˜åˆ¶æ›²çº¿
plt.figure(figsize=(10, 5))
plt.plot(history['train_loss'], label='Train Loss')
plt.plot(history['val_loss'], label='Val Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# ç»˜åˆ¶ F1 æ›²çº¿
plt.figure(figsize=(10, 5))
plt.plot(history['val_f1'], label='Val F1 Score', color='green')
plt.title('Validation F1 Score')
plt.xlabel('Epoch')
plt.ylabel('F1 Score')
plt.legend()
plt.show()
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
IMG_SIZE = 512

# è‡ªåŠ¨å¯»æ‰¾æ•°æ®é›†è·¯å¾„
POSSIBLE_ROOTS = [
    '/kaggle/input/recodai-luc-scientific-image-forgery-detection',
    '/kaggle/input/scientific-image-forgery-detection',
    './'
]
ROOT_DIR = None
for path in POSSIBLE_ROOTS:
    if os.path.exists(path) and os.path.exists(os.path.join(path, 'train_images')):
        ROOT_DIR = path
        break

if ROOT_DIR is None:
    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•ç¡¬ç¼–ç  (æ ¹æ®ä½ ä¹‹å‰çš„æŠ¥é”™ä¿¡æ¯)
    ROOT_DIR = '/kaggle/input/recodai-luc-scientific-image-forgery-detection'

TRAIN_IMG_DIR = os.path.join(ROOT_DIR, 'train_images')
AUTH_DIR = os.path.join(TRAIN_IMG_DIR, 'authentic')
FORGED_DIR = os.path.join(TRAIN_IMG_DIR, 'forged')
# ä¼˜å…ˆæ‰¾ Input é‡Œçš„ masksï¼Œå¦‚æœæ²¡æœ‰å†æ‰¾ working é‡Œçš„
MASK_DIR_OPT1 = os.path.join(ROOT_DIR, 'train_masks')
MASK_DIR = MASK_DIR_OPT1 if os.path.exists(MASK_DIR_OPT1) else os.path.join(TRAIN_IMG_DIR, 'train_masks')

print(f"Dataset Root: {ROOT_DIR}")
print(f"Mask Dir: {MASK_DIR}")


# ==========================================
# 2. é‡æ–°å®šä¹‰æ¨¡å‹ç»“æ„ (å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´)
# ==========================================
def build_model():
    model = smp.UnetPlusPlus(
        encoder_name="efficientnet-b4",
        encoder_weights=None,  # æ¨ç†ä¸éœ€è¦ä¸‹è½½ ImageNet æƒé‡
        in_channels=3,
        classes=1,
    )
    return model


# ==========================================
# 3. é‡æ–°å®šä¹‰æ•°æ®å¤„ç†ç±» (ä¿®å¤ç‰ˆ)
# ==========================================
class ScientificDatasetNPY(Dataset):
    def __init__(self, dataframe, transform=None):
        self.df = dataframe
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        image = cv2.imread(row['image_path'])
        if image is None:
            image = np.zeros((512, 512, 3), dtype=np.uint8)
        else:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        h, w = image.shape[:2]

        if row['mask_path'] is None:
            mask = np.zeros((h, w), dtype=np.float32)
        else:
            try:
                # è¯»å– .npy
                mask = np.load(row['mask_path'])
                mask = mask.astype(np.float32)
                if len(mask.shape) == 3: mask = mask.squeeze()  # å‹æ‰ 3D mask
                if mask.shape[:2] != (h, w):
                    mask = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)
            except:
                mask = np.zeros((h, w), dtype=np.float32)

        mask = np.where(mask > 0.5, 1.0, 0.0).astype(np.float32)
        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask']
        return image, mask.unsqueeze(0)


def get_transforms():
    return A.Compose([A.Resize(IMG_SIZE, IMG_SIZE), A.Normalize(), ToTensorV2()])


# ==========================================
# 4. å°è¯•åŠ è½½æ¨¡å‹æƒé‡
# ==========================================
MODEL_PATH = "best_model.pth"  # é»˜è®¤åœ¨å½“å‰ç›®å½•

if not os.path.exists(MODEL_PATH):
    # å°è¯•åœ¨ input é‡Œæ‰¾ (å¦‚æœä½ æ˜¯é€šè¿‡ Add Data æ·»åŠ çš„)
    possible_paths = glob.glob('/kaggle/input/**/best_model.pth', recursive=True)
    if possible_paths:
        MODEL_PATH = possible_paths[0]
    else:
        print("âŒ é”™è¯¯ï¼šåœ¨å½“å‰ç›®å½•æˆ– Input ä¸­æ‰¾ä¸åˆ° best_model.pthï¼")
        print("è¯·ç¡®è®¤ä½ ä¹‹å‰æ˜¯å¦è®­ç»ƒå¹¶ä¿å­˜äº†æ¨¡å‹ã€‚å¦‚æœæ–‡ä»¶ä¸¢å¤±ï¼Œå¿…é¡»é‡æ–°è¿è¡Œè®­ç»ƒä»£ç ã€‚")
        # è¿™é‡ŒæŠ›å‡ºå¼‚å¸¸åœæ­¢è¿è¡Œï¼Œé¿å…åé¢æŠ¥é”™
        raise FileNotFoundError("Model file not found.")

print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_PATH}")
model = build_model()
checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)

# è‡ªåŠ¨ä¿®å¤ DataParallel çš„ 'module.' å‰ç¼€
if 'module.' in list(checkpoint.keys())[0]:
    new_state_dict = {k.replace('module.', ''): v for k, v in checkpoint.items()}
    model.load_state_dict(new_state_dict)
else:
    model.load_state_dict(checkpoint)

model.to(DEVICE)
model.eval()
print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼å‡†å¤‡æµ‹è¯•...")

# ==========================================
# 5. å‡†å¤‡æµ‹è¯•æ•°æ® (åªæ‰¾ä¼ªé€ å›¾è¿›è¡Œå¯è§†åŒ–)
# ==========================================
# å¿«é€Ÿæ„å»ºä¸€ä¸ªåªåŒ…å« Forged å›¾ç‰‡çš„ä¸´æ—¶ DataFrame
forged_img_files = sorted(glob.glob(os.path.join(FORGED_DIR, '*.*')))
mask_npy_files = glob.glob(os.path.join(MASK_DIR, '*.npy'))
mask_map = {os.path.basename(m).split('.')[0]: m for m in mask_npy_files}

data = []
for img_path in forged_img_files:
    case_id = os.path.basename(img_path).split('.')[0]
    if case_id in mask_map:
        data.append({'image_path': img_path, 'mask_path': mask_map[case_id]})

if not data:
    print("âŒ è­¦å‘Šï¼šæœªåŒ¹é…åˆ°ä»»ä½•ä¼ªé€ æ•°æ®ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")
else:
    # éšæœºå– 5 å¼ 
    val_df = pd.DataFrame(data).sample(n=min(5, len(data)), random_state=42)
    val_ds = ScientificDatasetNPY(val_df, transform=get_transforms())
    val_loader = DataLoader(val_ds, batch_size=5, shuffle=False)

    # ==========================================
    # 6. å¯è§†åŒ–å¯¹æ¯” (åŸå›¾ vs çœŸå€¼ vs é¢„æµ‹)
    # ==========================================
    print("ğŸš€ æ­£åœ¨ç”Ÿæˆå¯¹æ¯”å›¾...")
    images, true_masks = next(iter(val_loader))
    images = images.to(DEVICE)

    with torch.no_grad():
        preds = model(images)
        preds = torch.sigmoid(preds)

    # è½¬ CPU
    images = images.cpu().numpy()
    true_masks = true_masks.numpy()
    preds = preds.cpu().numpy()

    # åå½’ä¸€åŒ–
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])

    fig, axes = plt.subplots(len(images), 3, figsize=(12, 4 * len(images)))
    if len(images) == 1: axes = np.expand_dims(axes, axis=0)  # å…¼å®¹å•å¼ å›¾

    for i in range(len(images)):
        # A. åŸå›¾
        img = images[i].transpose(1, 2, 0)
        img = img * std + mean
        img = np.clip(img, 0, 1)
        axes[i, 0].imshow(img)
        axes[i, 0].set_title("Original Image")
        axes[i, 0].axis('off')

        # B. çœŸå€¼ (Ground Truth)
        axes[i, 1].imshow(true_masks[i].squeeze(), cmap='gray', vmin=0, vmax=1)
        axes[i, 1].set_title("Ground Truth (Real)")
        axes[i, 1].axis('off')

        # C. é¢„æµ‹ (Prediction)
        # äºŒå€¼åŒ–æ˜¾ç¤º
        p_mask = (preds[i].squeeze() > 0.5).astype(np.float32)
        axes[i, 2].imshow(p_mask, cmap='gray', vmin=0, vmax=1)
        axes[i, 2].set_title("Prediction (Model)")
        axes[i, 2].axis('off')

    plt.tight_layout()
    plt.show()